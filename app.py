import streamlit as st
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.openai import OpenAIEmbedding
import os
from dotenv import load_dotenv

load_dotenv()

# Configure Global Settings for Bengali Support
Settings.llm = OpenAI(model="gpt-4o", temperature=0.3)
Settings.embed_model = OpenAIEmbedding(model="text-embedding-3-large")

# --- Page Config ---
st.set_page_config(page_title="Rannaghorer Ostad AI", page_icon="ü•ò", layout="centered")
st.title("ü•ò ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßÄ ‡¶∞‡¶æ‡¶®‡ßç‡¶®‡¶æ‡¶∞ ‡¶ì‡¶∏‡ßç‡¶§‡¶æ‡¶¶ (Bangla Chef AI)")
st.markdown("‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶¨‡ßç‡¶Ø‡¶ï‡ßç‡¶§‡¶ø‡¶ó‡¶§ ‡¶∂‡ßá‡¶´‡•§ ‡¶Ø‡ßá‡¶ï‡ßã‡¶®‡ßã ‡¶∞‡ßá‡¶∏‡¶ø‡¶™‡¶ø‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶∏‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®!")

# --- Setup LlamaIndex ---
@st.cache_resource(show_spinner=False)
def load_data():
    with st.spinner("‡¶∞‡ßá‡¶∏‡¶ø‡¶™‡¶ø ‡¶¨‡¶á ‡¶™‡ßú‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá... (Indexing recipes)..."):
        # Ensure your PDF is in the 'data' folder
        if not os.path.exists("./data"):
            st.error("Please create a folder named 'data' and put your Recipe PDF inside.")
            return None
            
        reader = SimpleDirectoryReader(input_dir="./data", recursive=True)
        docs = reader.load_data()
        index = VectorStoreIndex.from_documents(docs)
        return index

# Initialize Index
index = load_data()

if index:
    # Bengali System Prompt
    bengali_system_prompt = """
    ‡¶Ü‡¶™‡¶®‡¶ø ‡¶è‡¶ï‡¶ú‡¶® ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßÄ ‡¶∂‡ßá‡¶´ (‡¶¨‡¶æ‡¶¨‡ßÅ‡¶∞‡ßç‡¶ö‡¶ø)‡•§ ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶®‡¶æ‡¶Æ '‡¶∞‡¶®‡ßç‡¶ß‡¶® ‡¶ì‡¶∏‡ßç‡¶§‡¶æ‡¶¶'‡•§
    
    ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶æ‡¶¨‡¶≤‡ßÄ:
    ‡ßß. ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶∏‡¶∞‡ßç‡¶¨‡¶¶‡¶æ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶Ø‡¶º ‡¶¶‡ßá‡¶¨‡ßá‡¶® (‡¶Ø‡¶¶‡¶ø ‡¶®‡¶æ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞‡¶ï‡¶æ‡¶∞‡ßÄ ‡¶á‡¶Ç‡¶∞‡ßá‡¶ú‡¶ø‡¶§‡ßá ‡¶ö‡¶æ‡¶Ø‡¶º)‡•§
    ‡ß®. ‡¶∞‡¶æ‡¶®‡ßç‡¶®‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶ß‡¶æ‡¶™ ‡¶∏‡ßç‡¶™‡¶∑‡ßç‡¶ü‡¶≠‡¶æ‡¶¨‡ßá ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ñ‡ßç‡¶Ø‡¶æ ‡¶ï‡¶∞‡¶¨‡ßá‡¶®‡•§
    ‡ß©. ‡¶â‡¶™‡¶ï‡¶∞‡¶£‡ßá‡¶∞ ‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡¶∞‡ßá ‡¶ñ‡¶æ‡¶Å‡¶ü‡¶ø ‡¶®‡¶æ‡¶Æ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßá‡¶® (‡¶Ø‡ßá‡¶Æ‡¶®: ‡¶∏‡¶Ø‡¶º‡¶æ‡¶¨‡¶ø‡¶® ‡¶§‡ßá‡¶≤‡ßá‡¶∞ ‡¶¨‡¶¶‡¶≤‡ßá '‡¶∏‡¶∞‡¶ø‡¶∑‡¶æ‡¶∞ ‡¶§‡ßá‡¶≤', '‡¶™‡¶æ‡¶Å‡¶ö ‡¶´‡ßã‡ßú‡¶®')‡•§
    ‡ß™. ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞‡¶ï‡¶æ‡¶∞‡ßÄ‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶¨‡¶®‡ßç‡¶ß‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶Ü‡¶ö‡¶∞‡¶£ ‡¶ï‡¶∞‡¶¨‡ßá‡¶®‡•§
    """

    chat_engine = index.as_chat_engine(
        chat_mode="context", 
        system_prompt=bengali_system_prompt
    )

    # --- Chat Interface ---
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "‡¶Ü‡¶∏‡¶∏‡¶æ‡¶≤‡¶æ‡¶Æ‡ßÅ ‡¶Ü‡¶≤‡¶æ‡¶á‡¶ï‡ßÅ‡¶Æ! ‡¶Ü‡¶ú ‡¶ï‡ßÄ ‡¶∞‡¶æ‡¶®‡ßç‡¶®‡¶æ ‡¶ï‡¶∞‡¶§‡ßá ‡¶ö‡¶æ‡¶®?"}
        ]

    # Display chat history
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # User input
    if prompt := st.chat_input("‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶ï‡¶∞‡ßÅ‡¶® (‡¶Ø‡ßá‡¶Æ‡¶®: ‡¶ï‡¶æ‡¶ö‡ßç‡¶ö‡¶ø ‡¶¨‡¶ø‡¶∞‡¶ø‡ßü‡¶æ‡¶®‡¶ø ‡¶ï‡ßÄ‡¶≠‡¶æ‡¶¨‡ßá ‡¶∞‡¶æ‡¶Å‡¶ß‡¶¨‡ßã?)"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Generate response
        with st.chat_message("assistant"):
            with st.spinner("‡¶∂‡ßá‡¶´ ‡¶ö‡¶ø‡¶®‡ßç‡¶§‡¶æ ‡¶ï‡¶∞‡¶õ‡ßá‡¶®..."):
                response = chat_engine.chat(prompt)
                st.markdown(response.response)
                st.session_state.messages.append({"role": "assistant", "content": response.response})